%\VignetteEngine{knitr::knitr}
\documentclass{article}
\usepackage{graphicx, verbatim}
\usepackage[utf8]{inputenc}

<<style-knitr, eval=TRUE, echo=FALSE, results="asis">>=
BiocStyle::latex()
@

<<cache everything, include=FALSE>>=
knitr::opts_chunk$set(cache=TRUE)
@

\begin{document}

\bioctitle[nowaclean]{Cleaning the NOWAC postdiagnostic data set with
  \Rpackage{nowaclean}}
\author{Einar Holsb√∏\footnote{einar@cs.uit.no}}
\maketitle

\begin{abstract}
This vignette describes the cleaning of the NOWAC postdiagnostic microarray data
set with the \Rpackage{nowaclean} \R{} package, which implements the standard
operating procedure for detecting and removing technical outliers in the NOWAC
microarray data.
\end{abstract}

\section{Introduction}
This vignette describes the data cleaning performed on the Norwegian Women and
Cancer (NOWAC) postdiagnostic data set. The data cleaning process starts out
with some preprocessing where we remove some uninformative probes and some
samples where the controls have since gotten cancer (and can hence no longer be
considered healthy controls); this is shown in Section~\ref{section:preprocessing}.
Section~\ref{section:package} briefly describes the \Rpackage{nowaclean} \R{} package.
Section~\ref{section:outliers} describes the removal of technical outliers.

\subsection{Session info}
<<session_info, echo=FALSE, results="asis">>=
toLatex(sessionInfo())
@


\section{\Rpackage{nowaclean}}\label{section:package}
\subsection{Installation and loading}
Currently \Rpackage{nowaclean} is hosted only on
GitHub.\footnote{\url{https://github.com}} To install from GitHub you need to install
the \CRANpkg{devtools} package.
<<devtools, eval=FALSE>>=
install.packages("devtools")
@

Once you have installed \CRANpkg{devtools}, you can use it to install
\Rpackage{nowaclean} from its GitHub repository.
<<nowaclean_install, eval=FALSE>>=
library(devtools)
install_github("3inar/nowaclean")
@
Once it is installed, you can use \Rpackage{nowaclean} like you would any other \R{}
package.
<<nowaclean_load>>=
library(nowaclean)
@

\section{Loading and Preprocessing}\label{section:preprocessing}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PREPROCESSING
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
So now we load the dataset; we have suppressed the huge text dump that happens
when you load the \Rpackage{lumi} package:
<<load_data, message=FALSE>>=
library(lumi)  # Required to access LumiBatch objects
datapath <- "/project/data1/tice2/PostDiagnostic/GRC-244_postdiagnostic.RData"
load(datapath)
class(grc244)
dim(grc244)

# friendlier names
data <- grc244 # p x n
labInfo <- overview.data
negCtrl <- negativeCtrls
@
The \Rcode{grc244} object is a \Rcode{LumiBatch} object that contains 47323
probes for 868 samples.

\subsection{Remove blood type probes}
We'll now remove some probes to do with blood type that aren't especially
interesting w.r.t cancer. The \Rfunction{blood\_probes} function returns the
nuIDs of these probes.
<<names and hist>>=
histo_boolean <- !rownames(data) %in% blood_probes()
data <- data[histo_boolean, ]

# also extract gene expression matrix, transpose to get samples by probes
expression <- t(exprs(data))
@

\subsection{Load background variables}
Next up is to import background data such as case--control status and similar:
<<load bg>>=
bgpath <- "/project/data1/tice2/PostDiagnostic/postdiagnostic_background.csv"
background <- read.csv2(bgpath, na.strings="")

# I want the labnr, LPNR, match_labnr to be strings
str(background[, 1:4])  # they anren't
background$labnr <- as.character(background$labnr)
background$match_labnr <- as.character(background$match_labnr)
background$LPNR <- as.character(background$LPNR)

# More useful row names:
rownames(background) <- background$labnr

#sort the background table same as gene expression matrix
background_full <- background
background <- background[sampleNames(data), ]
@

\subsection{Remove pairs where the control has cancer}
There are two samples in the gene expression matrix that aren't in the background
info table. There are also some samples that we have background info for that
aren't in the gene expression matrix, but that is less interesting right now.
<<missing samples>>=
wrong <- which(!rownames(background) == sampleNames(data))
cbind(rownames(background)[wrong], sampleNames(data)[wrong])
missing_background <- sampleNames(data)[wrong]

# Are there cases without controls or controls without cases in the bg table?
unique(c(which(!background$labnr %in% background$match_labnr),
       which(!background$match_labnr %in% background$labnr)))
@

Luckily all the cases have controls and vice versa in the background table. Also
the two strange samples are most likely replicate samples (see below) so
it shouldn't be any problem to remove them.

<<replicates>>=
missing_background
replicates <- c(which(rownames(background) %in% c("102938", "103192")))
background[replicates, 1:5]
@

We also want to remove case-control pairs where the control since has gotten cancer.
You get this list from one of the people who deal with the cancer registry. These
controls will be removed along with the cases they correspond to.

<<subsetting>>=
sick_controls <- unique(c("100069", "100999", "101148", "102688", "104043", "104186",
                   "104872", "106508", "132668", "133111", "133383", "136514",
                   "139281", "144168", "145025", "145405", "146667"))
lone_cases <- background[sick_controls, "match_labnr"]

remove <- unique(c(sick_controls, lone_cases, missing_background))

# NB: We have an older version of R which means we have an older version of
# bioconductor and hence an older v of lumi. This means that subsetting by
# logical vector ruins lumibatch-objects. We'll do it by index instead.
# This bug should be fixed  in lumi version 2.19.1 according to here:
# https://support.bioconductor.org/p/65416/
remove_index <- match(remove, sampleNames(data))
data <- data[, -remove_index]
background <- background[-remove_index, ]
dim(data)
dim(background)
@

\subsection{Imputation}
The gene expression matrix contains some negative values, which first makes little
biological sense and, second, will be a problem once we try to take logarithms of
these values later. The consensus on the internet seems to be that negative gene
expression values can sometimes happen and that it is most likely due to some
correction procedure on the scanner level, i.e.\ long before we get the data.
We will impute these values using the \Rfunction{knn.impute} from the
\Biocpkg{impute} package.

<<impute1>>=
library(impute)  # from bioconductor
expression <- exprs(data)
impute_index = which(expression < 0, arr.ind=T)
expression[impute_index] # there are three of them
@
The \Rfunction{impute.knn} function produces a lot of annoying debug output, which
I have suppressed in this document.
<<impute2, results="hide">>=
expression[impute_index] <- NA # so that knn.impute knows what to impute
expression_imputed <- impute.knn(expression)$data
@

Let's check whether the imputed values make sense:
<<check_imputations>>=
check <- cbind(original=exprs(data)[impute_index], imputed=expression_imputed[impute_index])
check <- cbind(check, probe_minimum=apply(expression[rownames(impute_index), ], 1, min, na.rm=T))
check
@

This is close enough considering that the gene expression values range from
the order of  ten to the order of tens of thousands. We'll put the imputed gene
expression matrix into the \Rcode{LumiBatch} object to replace the old one. This
completes the preprocessing.
<<replace expressions>>=
exprs(data) <- expression_imputed
any(exprs(data) < 0)
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%      OUTLIER REMOVAL
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Outlier Removal}\label{section:outliers}
The outlier detection process involves lots of exploratory plotting where we visualize
clustering (dendrogram plots), spatial distribution (PCA), gene expression densities
individual vs. median individual plots (sort of like a q-q plot).
(TODO: bland-altman? MA plot? What's the difference?)

We do outlier removal twice to be sure everyting looks well-behaved; let's just
start on round one.

%%% AQM NEEDED
We'll look at a couple of summary plots. I'll time them for the sake of
curiosity.
<<initialQC>>=
# The following line is afaik uninteresting and slow
#system.time(dataQ <- lumiQ(data))  #initial QC with lumi. v slow

# pooled probe intensities per sample. Hard to use with 800ish samples
system.time(plot(data, what="density"))

# MDS sample relation takes a long time and is probably risky to use due to
# its trying to preserve distances between points & distance measures being notoriously
# unreliable in higher dimensions (intuition completely breaks down around 10 dimensions)
#system.time(plot(data, what="sampleRelation", method="mds"))   # MDS sample relation? Takes 12 minutes

# dendrogram. slow but nice to look at. Same as 'dendrogram', but includes
# a nice outlier line
system.time(plot(data, what="outlier"))
@

As we can see, with over 800 samples, these plots can be difficult to read, we
do however see that ther eis a handful of samples with strange probe intensity
distributions, and that two samples are very far from the centre of our samples.
Let's just move on and look at a PCA plot.

<<PCA>>=
# case-control mappings
cases <- background[background$Case_ctrl == "case", ]$labnr
controls <- background[cases,]$match_labnr
l2expr <- log2(t(exprs(data))) # transpose for samples by probes
diffl2expr <- l2expr[cases, ] - l2expr[controls, ]

prc <- prcomp(l2expr)
@

\end{document}
