%\VignetteEngine{knitr::knitr}
\documentclass{article}
\usepackage{graphicx, verbatim}
\usepackage[utf8]{inputenc}

<<style-knitr, eval=TRUE, echo=FALSE, results="asis">>=
BiocStyle::latex()
@

<<cache everything, include=FALSE>>=
knitr::opts_chunk$set(cache=TRUE)
@

\begin{document}

\bioctitle[nowaclean]{Cleaning the NOWAC postdiagnostic data set with
  \Rpackage{nowaclean}}
\author{Einar Holsb√∏\footnote{einar@cs.uit.no}}
\maketitle

\begin{abstract}
This vignette describes the cleaning of the NOWAC postdiagnostic microarray data
set with the \Rpackage{nowaclean} \R{} package, which implements the standard
operating procedure for detecting and removing technical outliers in the NOWAC
microarray data.
\end{abstract}

\section{Introduction}
This vignette describes the data cleaning performed on the Norwegian Women and
Cancer (NOWAC) postdiagnostic data set. The data cleaning process starts out
with some preprocessing where we remove some uninformative probes and some
samples where the controls have since gotten cancer (and can hence no longer be
considered healthy controls); this is shown in Section~\ref{section:preprocessing}.
Section~\ref{section:package} briefly describes the \Rpackage{nowaclean} \R{} package.
Section~\ref{section:outliers} describes the removal of technical outliers.

\subsection{Session info}
<<session_info, echo=FALSE, results="asis">>=
toLatex(sessionInfo())
@


\section{\Rpackage{nowaclean}}\label{section:package}
\subsection{Installation and loading}
Currently \Rpackage{nowaclean} is hosted only on
GitHub.\footnote{\url{https://github.com}} To install from GitHub you need to install
the \CRANpkg{devtools} package.
<<devtools, eval=FALSE>>=
install.packages("devtools")
@

Once you have installed \CRANpkg{devtools}, you can use it to install
\Rpackage{nowaclean} from its GitHub repository.
<<nowaclean_install, eval=FALSE>>=
devtools::install_github("3inar/nowaclean")
@
Once it is installed, you can use \Rpackage{nowaclean} like you would any other \R{}
package.
<<nowaclean_load>>=
library(nowaclean)
@

\section{Loading and Preprocessing}\label{section:preprocessing}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PREPROCESSING
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
So now we load the dataset; we have suppressed the huge text dump that happens
when you load the \Rpackage{lumi} package:
<<load_data, message=FALSE>>=
library(lumi)  # Required to access LumiBatch objects
datapath <- "/project/data1/tice2/PostDiagnostic/GRC-244_postdiagnostic.RData"
load(datapath)
class(grc244)
dim(grc244)

# friendlier names
data <- grc244 # p x n
labInfo <- overview.data
negCtrl <- negativeCtrls
@
The \Rcode{grc244} object is a \Rcode{LumiBatch} object that contains 47323
probes for 868 samples.

\subsection{Remove blood type probes}
We'll now remove some probes to do with blood type that aren't especially
interesting w.r.t cancer. The \Rfunction{blood\_probes} function returns the
nuIDs of these probes.
<<names and hist>>=
histo_boolean <- !rownames(data) %in% blood_probes()
data <- data[histo_boolean, ]

# also extract gene expression matrix, transpose to get samples by probes
expression <- t(exprs(data))
@

\subsection{Load background variables}
Next up is to import background data such as case--control status and similar:
<<load bg>>=
bgpath <- "/project/data1/tice2/PostDiagnostic/postdiagnostic_background.csv"
background <- read.csv2(bgpath, na.strings="")

# I want the labnr, LPNR, match_labnr to be strings
str(background[, 1:4])  # they anren't
background$labnr <- as.character(background$labnr)
background$match_labnr <- as.character(background$match_labnr)
background$LPNR <- as.character(background$LPNR)

# More useful row names:
rownames(background) <- background$labnr

#sort the background table same as gene expression matrix
background_full <- background
background <- background[sampleNames(data), ]
@

\subsection{Remove pairs where the control has cancer}
There are two samples in the gene expression matrix that aren't in the background
info table. There are also some samples that we have background info for that
aren't in the gene expression matrix, but that is less interesting right now.
<<missing samples>>=
wrong <- which(!rownames(background) == sampleNames(data))
cbind(rownames(background)[wrong], sampleNames(data)[wrong])
missing_background <- sampleNames(data)[wrong]

# Are there cases without controls or controls without cases in the bg table?
unique(c(which(!background$labnr %in% background$match_labnr),
       which(!background$match_labnr %in% background$labnr)))
@

Luckily all the cases have controls and vice versa in the background table. Also
the two strange samples are most likely replicate samples (see below) so
it shouldn't be any problem to remove them.

<<replicates>>=
missing_background
replicates <- c(which(rownames(background) %in% c("102938", "103192")))
background[replicates, 1:5]
@

We also want to remove case-control pairs where the control since has gotten cancer.
You get this list from one of the people who deal with the cancer registry. These
controls will be removed along with the cases they correspond to.

<<subsetting>>=
sick_controls <- unique(c("100069", "100999", "101148", "102688", "104043", "104186",
                   "104872", "106508", "132668", "133111", "133383", "136514",
                   "139281", "144168", "145025", "145405", "146667"))
lone_cases <- background[sick_controls, "match_labnr"]

remove <- unique(c(sick_controls, lone_cases, missing_background))

# NB: We have an older version of R which means we have an older version of
# bioconductor and hence an older v of lumi. This means that subsetting by
# logical vector ruins lumibatch-objects. We'll do it by index instead.
# This bug should be fixed  in lumi version 2.19.1 according to here:
# https://support.bioconductor.org/p/65416/
remove_index <- match(remove, sampleNames(data))
data <- data[, -remove_index]
background <- background[-remove_index, ]
dim(data)
dim(background)
@

\subsection{Imputation}
The gene expression matrix contains some negative values, which first makes little
biological sense and, second, will be a problem once we try to take logarithms of
these values later. The consensus on the internet seems to be that negative gene
expression values can sometimes happen and that it is most likely due to some
correction procedure on the scanner level, i.e.\ long before we get the data.
We will impute these values using the \Rfunction{knn.impute} from the
\Biocpkg{impute} package.

<<impute1>>=
library(impute)  # from bioconductor
expression <- exprs(data)
impute_index = which(expression < 0, arr.ind=T)
expression[impute_index] # there are three of them
@
The \Rfunction{impute.knn} function produces a lot of annoying debug output, which
I have suppressed in this document.
<<impute2, results="hide">>=
expression[impute_index] <- NA # so that knn.impute knows what to impute
expression_imputed <- impute.knn(expression)$data
@

Let's check whether the imputed values make sense:
<<check_imputations>>=
check <- cbind(original=exprs(data)[impute_index], imputed=expression_imputed[impute_index])
check <- cbind(check, probe_minimum=apply(expression[rownames(impute_index), ], 1, min, na.rm=T))
check
@

This is close enough considering that the gene expression values range from
the order of  ten to the order of tens of thousands. We'll put the imputed gene
expression matrix into the \Rcode{LumiBatch} object to replace the old one. This
completes the preprocessing.
<<replace expressions>>=
exprs(data) <- expression_imputed
any(exprs(data) < 0)
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%      OUTLIER REMOVAL
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Outlier Removal}\label{section:outliers}
The outlier detection process involves lots of exploratory plotting where we visualize
clustering (dendrogram plots), spatial distribution (PCA), gene expression densities
individual vs. median individual plots (sort of like a q-q plot).
(TODO: bland-altman? MA plot? What's the difference?)

We do outlier removal twice to be sure everyting looks well-behaved; let's just
start on round one.

%%% AQM NEEDED
We'll look at a couple of summary plots. I'll time them for the sake of
curiosity.
<<initialQC>>=
# The following line is afaik uninteresting and slow
#system.time(dataQ <- lumiQ(data))  #initial QC with lumi. v slow

# pooled probe intensities per sample. Hard to use with 800ish samples
system.time(plot(data, what="density"))

# dendrogram. slow but nice to look at. Same as 'dendrogram', but includes
# a nice outlier line
system.time(plot(data, what="outlier"))/60
@

As we can see, with over 800 samples, these plots can be difficult to read, we
do however see that ther eis a handful of samples with strange probe intensity
distributions, and that two samples are very far from the centre of our samples.
Let's just move on and look at a PCA plots. The left panel shows all of the
observations: cases and controls. The right panel shows $\log_2$ case--control
fold change. The contour lines show distance to the center of the data in number
of standard deviations.

<<PCA>>=
# case-control mappings
cases <- background[background$Case_ctrl == "case", ]$labnr
controls <- background[cases,]$match_labnr
l2expr <- log2(t(exprs(data))) # transpose for samples by probes
diffl2expr <- l2expr[cases, ] - l2expr[controls, ]

prc_all <- prcout(l2expr)
prc_diff <- prcout(diffl2expr)

par(mfrow=c(1,2))
plot(prc_all)
plot(prc_diff)
@

The points marked in red are two standard deviations or more away from the
main bulk of the data, at least the points that are above standard deviations
away look very suspicious. Let's keep these red points as possible outliers.

<<pcaoutliers>>=
# predict() returns logical vectors of differing lenght,
# it's __very__ important to translate these to sample names
# so that you don't fool yourself later on.
pca_outliers <- unique(
  c(rownames(l2expr)[predict(prc_all, sdev=3)],
  rownames(diffl2expr)[predict(prc_diff, sdev=3)])
)
pca_outliers
@

Next up, AQM
<<AQMtest>>=
library(arrayQualityMetrics) #TODO move this

data2 <- data
exprs(data2) <- expression_imputed
eset <- as(data2, "ExpressionSetIllumina")
class(eset)
preparedData = prepdata(expressionset=eset, intgroup=c(), do.logtransform=TRUE)

system.time(bo <- aqm.boxplot(preparedData))
system.time(maplott <- aqm.maplot(preparedData))
system.time(heat <- aqm.heatmap(preparedData))
@

The boxplot method is apparently very slow so we've made our own:
<<boxplot_nowaclean>>=
system.time(boxo <- boxout(l2expr))
plot(boxo)
@

Points on the lines in this plot represent the box and whiskers of your regular
\Rfunction{boxplot} function for your arrays. The lines represent the first and
third quartiles, the median (viz the standard box), and the most extreme
points that fall within 1.5 times the interquartile range (viz the standard whiskers).
As default the arrays are sorted by size of ks statistic (distance to pooled empirical distribution
function).The red line demarks the cutoff for outlier or not.

We can order by batch-effect by passing a batch vector to the plot method:

<<boxplot_batch>>=
# batch by plate (possibly) setting rownames to have an easier time
# getting the correct values in the correct order (subset by rowname)
rownames(labInfo) <- labInfo$Sample_ID
plateno <- labInfo[rownames(l2expr),]$Plate

# how many plates are there
length(unique(plateno))

plot(boxo, batch=plateno)
@

There is a bit of a strange bump between the last two plates, let's see what
happens if we look at $\log_2$ fold change instead:

<<batch_diff>>=
box_diff <- boxout(diffl2expr)

plateno <- labInfo[rownames(diffl2expr),]$Plate

plot(box_diff)
plot(box_diff, batch=plateno)
@

The strange plate effect seems to disappear in this case. There are still some
clear outliers. Let's get the flagged outliers from both of these.

<<get_outliers_boxout>>=
boxplot_outliers <- union(
  rownames(l2expr)[predict(boxo, sdev=3)],
  rownames(diffl2expr)[predict(box_diff, sdev=3)]
)

length(boxplot_outliers)
@

35 outliers is probably much too many based on what we saw in the pca plot,
which just goes to show that you have be careful about automating this stuff too
much.

The final detection method we consider is the MA-plot. This was also slow enough
in AQM that we decided to make our own. Let's plot the worst candidates (diverge the most from
the horizontal line at 0) and compare to some random samples.
<<maplot>>=
system.time(maout <- mapout(l2expr))
plot(maout, nout=5, lineup=T)

mapoutliers <- rownames(l2expr)[predict(maout, sdev=3)]
length(mapoutliers)
@

Let's now combine all outlier vectors.

<<outlier_intersect>>=
out_intersect <- union(mapoutliers, boxplot_outliers)
length(out_intersect)

out_dendrogram <- c("126897", "141068") # these were hard to read off the plot


outliers <- unique(c(out_dendrogram, pca_outliers, out_intersect))
outliers
@

<<>>=
densities <- dens(l2expr)
plot(densities, outliers=outliers)
@


\end{document}
